# Google-like Search Engine Design â€” 30-Minute Interview Guide

## 1ï¸âƒ£ REQUIREMENTS CLARIFICATION (3-4 minutes)

### ğŸ¯ Core Objective
Design a web search engine that can index billions of web pages and serve search queries with sub-second latency.

### âœ… Functional Requirements
- **Web Crawling**: Discover and fetch web pages across the internet
- **Indexing**: Process and store searchable content efficiently  
- **Query Processing**: Parse user queries and return relevant results
- **Ranking**: Order results by relevance and authority
- **Real-time Updates**: Handle new/updated content continuously

### ğŸ”’ Non-Functional Requirements
- **Scale**: 100M daily active users, 10B pages indexed
- **Performance**: <200ms query response time
- **Availability**: 99.99% uptime
- **Throughput**: 100K queries per second (peak)
- **Storage Efficiency**: Petabyte-scale data management

---

## 2ï¸âƒ£ CAPACITY ESTIMATION (4-5 minutes)

### ğŸ“Š Traffic & Storage Analysis

| Metric | Estimate | Calculation |
|--------|----------|-------------|
| **Daily Active Users** | 100M | Given |
| **Queries per User/Day** | 50 | Industry average |
| **Total Daily Queries** | 5B | 100M Ã— 50 |
| **Peak QPS** | 100K | 5B Ã· 86,400 Ã— 2 (peak factor) |
| **Average QPS** | 50K | 5B Ã· 86,400 |

### ğŸ’¾ Storage Requirements

| Component | Size | Notes |
|-----------|------|-------|
| **Raw Web Pages** | 10 PB | 10B pages Ã— 1MB average |
| **Processed Content** | 3-5 PB | After cleaning/tokenization |
| **Inverted Index** | 500-800 GB | Compressed tokens â†’ document mapping |
| **Forward Index** | 5 PB | Document metadata and content |
| **Link Graph** | 2 PB | Page relationships for PageRank |
| **Cache Layer** | 100-500 GB | Hot query results |

### ğŸ•·ï¸ Crawling Capacity
- **Target**: 10M pages/day for fresh content
- **Crawl Rate**: ~115 pages/second
- **Crawler Fleet**: 1000 distributed crawlers
- **Per Crawler**: 0.1-0.2 pages/second (respecting robots.txt)

---

## 3ï¸âƒ£ HIGH-LEVEL ARCHITECTURE (8-10 minutes)

### ğŸ—ï¸ System Architecture Diagram

```
                           GOOGLE-LIKE SEARCH ENGINE ARCHITECTURE
                                           
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ğŸ‘¥ USER INTERFACE LAYER                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Web Frontend   â”‚   Mobile Apps   â”‚   API Gateway   â”‚    Load Balancer    â”‚
â”‚  (React/Vue)    â”‚  (iOS/Android)  â”‚ (Rate Limiting) â”‚   (Nginx/HAProxy)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“ 100K QPS
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        âš¡ QUERY PROCESSING LAYER                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Query Parser   â”‚  Query Router   â”‚   Cache Layer   â”‚  Result Formatter   â”‚
â”‚ (NLP, Speller)  â”‚ (Shard Router)  â”‚ (Redis Cluster) â”‚ (Snippet Generator) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“ Index Lookup
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         ğŸ“š INDEX & SEARCH LAYER                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Inverted Index  â”‚ Forward Index   â”‚ Ranking Engine  â”‚   Link Graph DB     â”‚
â”‚ (Elasticsearch) â”‚ (Document Meta) â”‚(PageRank+ML)    â”‚  (Graph Database)   â”‚
â”‚   500-800 GB    â”‚      5 PB       â”‚                 â”‚       2 PB          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“ Content Feed
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ğŸ•·ï¸ CRAWLING & INDEXING LAYER                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚   URL Manager   â”‚  Crawler Fleet  â”‚Content Processorâ”‚   Index Builder     â”‚
â”‚(Queue+Schedule) â”‚(1000 Workers)   â”‚(Text Extraction)â”‚  (MapReduce)        â”‚
â”‚                 â”‚ 115 pages/sec   â”‚                 â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â†“ Data Storage
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ğŸ’¾ STORAGE LAYER                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Document Store  â”‚  Index Storage  â”‚  Metadata DB    â”‚   Backup & Replica  â”‚
â”‚   HDFS/GFS      â”‚   NoSQL Shards  â”‚  PostgreSQL     â”‚   Cross-DC Sync     â”‚
â”‚     10 PB       â”‚                 â”‚                 â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ—ï¸ Core Components

| Component | Responsibility | Technology Choice |
|-----------|---------------|-------------------|
| **URL Manager** | Crawl queue, deduplication, scheduling | Redis + PostgreSQL |
| **Crawler Service** | Fetch pages, extract content | Distributed Go/Java workers |
| **Content Processor** | Clean HTML, extract text/links | Apache Kafka + Spark |
| **Indexer** | Build inverted/forward indexes | Elasticsearch/Lucene |
| **Query Service** | Parse queries, retrieve results | Custom service + cache |
| **Ranking Engine** | Score and rank results | ML models + PageRank |
| **Storage Layer** | Distributed file system | HDFS/GFS + NoSQL |

### ğŸŒ API Design

```http
# Search API
GET /search?q={query}&page={n}&filters={type}
Response: {
  "results": [...],
  "total": 1000000,
  "time_ms": 150
}

# Crawler Management
POST /crawler/submit
Body: {"urls": ["http://example.com"]}

# Index Stats
GET /index/stats
Response: {"documents": 10000000000, "size_gb": 800000}
```

### ğŸ—„ï¸ Data Models

#### URL Queue Schema
```sql
CREATE TABLE url_queue (
  url_hash VARCHAR(64) PRIMARY KEY,
  url TEXT NOT NULL,
  domain VARCHAR(255),
  next_crawl_time TIMESTAMP,
  priority INT DEFAULT 5,
  retry_count INT DEFAULT 0,
  status ENUM('pending', 'crawling', 'done', 'failed')
);
```

#### Document Index Schema
```json
{
  "doc_id": "sha256_hash",
  "url": "https://example.com/page",
  "title": "Page Title",
  "content_tokens": ["word1", "word2"],
  "outbound_links": ["url1", "url2"],
  "pagerank_score": 0.85,
  "last_crawled": "2025-07-25T10:00:00Z",
  "language": "en"
}
```

#### Inverted Index Structure
```
Token: "machine learning"
Posting List: [
  {doc_id: "abc123", tf: 5, positions: [10, 45, 100]},
  {doc_id: "def456", tf: 3, positions: [5, 200, 350]},
  ...
]
```

---

## 4ï¸âƒ£ DETAILED DESIGN DEEP DIVES (10-12 minutes)

### ğŸ•·ï¸ Web Crawling System

**Architecture Pattern**: Producer-Consumer with Priority Queues

**Crawl Strategy**:
1. **Seed URLs** â†’ URL Manager assigns to crawler workers
2. **Politeness**: Respect robots.txt, rate limiting per domain
3. **Deduplication**: Content hashing to avoid duplicate processing
4. **Freshness**: Priority-based recrawling (news sites hourly, static sites monthly)

**Key Optimizations**:
- **Domain Partitioning**: Distribute crawlers by domain hash
- **Bloom Filters**: Fast duplicate URL detection
- **Content Diffing**: Only reindex changed content

### ğŸ“š Indexing Pipeline

**Processing Flow**:
```
Raw HTML â†’ Content Extraction â†’ Tokenization â†’ Index Building â†’ Storage
```

**Inverted Index Design**:
- **Sharding Strategy**: Partition by term hash for load distribution
- **Compression**: Delta encoding for document IDs, term frequency
- **Update Strategy**: Incremental updates + periodic full rebuilds

**Forward Index Benefits**:
- Fast document retrieval for result snippets
- Metadata storage (title, URL, timestamp)
- Link analysis data for PageRank

### ğŸ” Query Processing Engine

**Query Flow**:
1. **Parse**: Extract terms, operators, filters
2. **Optimize**: Query rewriting, spell correction
3. **Retrieve**: Parallel lookup across index shards
4. **Intersect**: Combine posting lists efficiently
5. **Rank**: Apply relevance scoring algorithms
6. **Format**: Generate result snippets and metadata

**Ranking Factors**:
- **TF-IDF**: Term frequency Ã— inverse document frequency
- **PageRank**: Link-based authority scoring
- **Freshness**: Recent content boost
- **User Signals**: Click-through rates, dwell time
- **Query Context**: Location, personalization

### âš¡ Caching Strategy

**Multi-Layer Caching**:
- **L1 - Query Cache**: Redis cluster for popular queries (TTL: 5-15 minutes)
- **L2 - Index Cache**: Hot index segments in memory
- **L3 - CDN**: Geographically distributed static content

**Cache Invalidation**:
- **Time-based**: TTL for different content types
- **Event-driven**: Real-time updates for breaking news
- **LRU Eviction**: Memory management for hot data

---

## 5ï¸âƒ£ SCALING & PERFORMANCE (3-4 minutes)

### ğŸ¯ Performance Optimizations

| Challenge | Solution | Impact |
|-----------|----------|---------|
| **Query Latency** | Index sharding + parallel processing | <200ms response |
| **Storage Costs** | Compression + tiered storage | 60% reduction |
| **Crawl Efficiency** | Distributed crawlers + smart scheduling | 10M pages/day |
| **Index Updates** | Incremental indexing + background merging | Real-time freshness |

### ğŸ”§ Bottleneck Resolutions

**Crawling Bottlenecks**:
- Bandwidth limits â†’ Geographically distributed crawlers
- Site rate limits â†’ Adaptive backoff strategies
- Duplicate detection â†’ Bloom filters + content hashing

**Indexing Bottlenecks**:
- Memory usage â†’ Segment-based indexing with compression
- I/O throughput â†’ SSD storage + batch processing
- Update conflicts â†’ Write-ahead logging + eventual consistency

**Query Bottlenecks**:
- High QPS â†’ Horizontal sharding + load balancing
- Complex queries â†’ Query optimization + result caching
- Global distribution â†’ Regional data centers + CDN

---

## 6ï¸âƒ£ MONITORING & RELIABILITY (2-3 minutes)

### ğŸ“Š Key Metrics
- **Crawl Health**: Pages/second, error rates, coverage
- **Index Freshness**: Average document age, update lag
- **Query Performance**: Latency P95/P99, QPS, cache hit rate
- **System Health**: CPU/memory usage, disk I/O, network throughput

### ğŸ›¡ï¸ Fault Tolerance
- **Data Replication**: 3x replication across availability zones
- **Service Redundancy**: Load balancers + auto-scaling groups
- **Graceful Degradation**: Serve stale results during outages
- **Circuit Breakers**: Prevent cascade failures

---

## 7ï¸âƒ£ INTERVIEW TIPS & TRADE-OFFS

### âœ… Key Discussion Points
1. **Consistency vs. Availability**: Eventual consistency for better performance
2. **Cost vs. Freshness**: Balance crawl frequency with infrastructure costs
3. **Relevance vs. Speed**: Complex ranking algorithms vs. query latency
4. **Centralized vs. Distributed**: Trade coordination complexity for scalability

### ğŸ¯ Impressive Details to Mention
- **MapReduce** for distributed index building
- **Consistent hashing** for shard distribution
- **Bloom filters** for memory-efficient duplicate detection
- **Machine learning** for query understanding and ranking
- **A/B testing** framework for ranking algorithm improvements

### ğŸš€ Follow-up Extensions
- **Image/Video search** capabilities
- **Real-time search** for social media content  
- **Personalization** and user behavior modeling
- **Mobile optimization** and voice search
- **Knowledge graph** integration for entity search

This design handles 100M users with sub-200ms latency while maintaining 99.99% availability through distributed architecture, intelligent caching, and fault-tolerant design patterns.